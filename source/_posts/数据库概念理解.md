---
title: 数据库概念理解
date: 2020-08-06 20:01:07
tags:
- 数据库
- mysql
---
# 数据库概念知识点

> 如何设计一个数据库？来，解释一下   
> 首先思考一个数据库的文件存在哪儿，文件系统的存储管理。  
> 然后文件存完以后要能方便地查询，使用sql语言，因此要支持sql地解析。  
> 为了让sql查找快一点，要支持索引。  
> 为了让相同的查询能减少性能损害，要支持缓存。
> 保证了速度以后还要保证数据安全，要支持锁。
> 为了保证所做的操作、sql不丢失，要支持日志。
> 为了防止数据被任何登入系统的人修改，要支持权限划分。
> 当数据库宕机以后要保证数据可以及时恢复，要做容灾管理。
## 事务是什么？
事务是满足ACID特性的一组操作。
- A Atomic原子性 一系列操作要么全部完成要么，要么全部不做
- C Consistency一致性 就是指所有事务（有许多事务）同一时刻对同一数据的读取结果是相同的、一致的
- I Isolation隔离性 指事务如果还没有提交，对其他事务不可见
- D Durability持久性 一旦事务提交数据就会永久保存到数据库中，不因为系统停止或者崩溃而导致数据丢失，执行了一半的事务数据也可以用【重做日志】进行恢复

> 【回滚日志undo Log】记录的是数据的逻辑修改，【重做日志 redo Log】记录的是数据页的物理修改，【二进制日志binlog】记录的是sql语句或者修改的数据行。  

>  **redo log** 是InnoDB引擎层的日志（层次），记录的是事务修改以后的物理页page的数据内容（存储内容），在事务执行过程中 就会不断写入redo log。作用就是确保事务的持久性，因为redo log有一个redo log buffer 默认8M，redo log事先写到这块内存，然后有三种策略保证redo log buffer的数据保存磁盘:   
> 1. Master Thread 每秒一次执行刷新Innodb_log_buffer到重做日志文件。
> 2. 每个事务提交时会将重做日志刷新到重做日志文件。
> 3. 当重做日志缓存可用空间 少于一半时，重做日志缓存被刷新到重做日志文件

>  **bin log** 是mysql层面的二进制日志，记录了所有引擎的日志（层次）。文件记录的格式设为STATEMENT（记录sql）还是ROW（记录每个修改的数据行的修改细节），又或者是MIXED，其记录的都是关于一个事务的具体操作内容，即该日志是逻辑日志（存储内容），bin log在事务提交的时候才会一次性的写入。作用是用于主从复制，数据恢复，增量备份。  
 
> **undo log** 是InnoDB引擎层的日志（层次），记录的是每个数据行的每个事务提交的多个版本的记录，通过回滚指针连在一起，是逻辑记录（存储内容）。在事务执行过程中 就会不断写入undo log。作用是用于事务回滚与MVCC快照读。    



事务的一致性是结果。

在单事务情况下无并发，只要满足原子性，就能达成数据一致性。

在多事务并发情况下，要满足原子性与隔离性才能达成数据一致性。


## 并发一致性问题
为什么会有并发问题呢？因为破坏了事务的隔离性，为了使多事务并发执行时，在一定程度上满足隔离性。
- 用户可以自己加锁来满足隔离性。
- 也可以直接使用数据库提供的默认加锁方案，即四种隔离级别。

## 加锁
### 封锁粒度
Mysql中有两种粒度，一种是行级锁、一种是表级锁
锁粒度越低，则系统并发程度越高 且 系统开销越大

### 锁类型
#### 读写锁
- 互斥锁 写锁 X
- 共享锁 读锁 S

||X|S|
|-|-|-|
|X|\\|\\|
|S|\\|共享|

#### 意向锁
> 为了解决一个问题，就是在给一个表加X锁之前要检查这个表里的每一行有没有加S锁或者X锁，然后才能决定能不能加X锁，很耗时。

意向锁 IX与IS均为表级锁
如果事务想要给表的某一数据行就S锁或X锁，可以先给表加对应的意向锁。

> 引入意向锁以后，一个事务给一个表加X锁之前只需要判断这个表有没有被其他事务加S/IS/X/IX锁，如果加了，这个事务就加锁失败了。

||X|IX|S|IS|
|-|-|-|-|-|
|X|\\|\\|\\|\\|
|IX|\\|O|\\|O|
|S|\\|\\|O|O|
|IS|\\|O|O|O|

**注意**:上面的兼容关系只针对表级锁，表级的IX或IS锁与行级的读写锁是兼容的噢。

即A事务与B事务同时读取表T，A读取行R1，B读取行R2，那么A与B可以同时对表T加意向写锁，然后A对R1加行级写锁，B对R2加行级写锁，两个事务的加锁都能成功。

### 封锁协议
#### 一级封锁协议
事务T要修改一个数据A必须加X锁，直到T结束释放。
> 加X锁可以避免修改丢失，如果是直接写原数据无所谓，但是如果是读写操作，就要避免数据丢失。
#### 二级封锁协议
一级的基础上+读取数据A必须加S锁，读取完释放。
> 加了读锁能避免脏读，即之前不加锁的话，写之前我读了一下，等
#### 三级封锁协议
二级的基础上+读取数据A必须加S锁，直到T结束了释放

### 两段锁协议
对所有事务的加锁与解锁操作，分为两个阶段进行，一个阶段完全执行所有事务的加各种锁的操作，加锁操作结束以后进入另一个阶段，即事务可以对其持有的锁开始释放。

这种方式的并发控制，能够使并发执行的结果与串行执行的事务结果相同。不会出现并发一致性的问题。

> lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B)

### 隐式锁定与显示锁定
Mysql的InnoDB存储引擎采用的是两段锁协议，而且根据隔离级别的需要自动加锁，并且所有锁在使用完以后同一时刻被释放，称为隐式加锁。

在sql语句中指定进行显示加锁:
> SELECT ... LOCK In SHARE MODE;  
> SELECT ... FOR UPDATE;

## 隔离级别
> 具体的加锁实现与InnoDB有关
- 未提交读 READ UNCOMMITTED  
    - 加锁程度最低，
    - A事务修改了值还没有提交，B事务就能直接读到这个值，会造成脏读，因为有可能A回滚了，你B读到的就是脏数据了。
- 读已提交 READ COMMITTED 
    - 加锁程度次低，
    - A事务修改的值只有提交以后，B事务才能读到，会有不可重复读的问题，因为两次读取之间会被其他事务修改。
- 可重复读 REPEATABLE READ
    - 保证一个事务中 多次读取的同一数据的结果是一致的，会有幻读的问题，对于Select操作无法判断数据条数是否变化。
- 可串行化 SERIALIZABLE
    - 事务串行执行，不会有隔离性的问题。

> 幻读的问题？  
> 
> 幻读：是指在同一个事务中，前后两次查询相同范围时，得到的结果不一致，后一次查询到新插入的行。 
>  
> 在InnoDB中，RR隔离级别下，普通的读是快照读，快照是事务开始前的最后一次Commit，所以快照读在本次事务期间永远不会有变化，所以幻读仅仅发生在当前读情况下。 
> 
> 在InnoDB的RR隔离级别下，还有一种锁就是间隔锁，能锁住除当前索引记录外前后间隔，而且只对插入操作互斥，不同的间隔锁兼容。


## MVCC 多版本并发控制
MVCC就是Mysql的InnoDB存储引擎实现隔离级别的一种方式。  
**未提交读** 读取最新的数据行，没有使用MVCC。  
**已提交读**
**可重复读** 这两种方式使用MVCC来实现。  
**可串行化** 要通过加读写锁实现，单纯使用MVCC无法实现

### 基本
MVCC利用的是多版本的思想，没有进行加锁操作。写操作更新数据最新版本的快照，读操作读的是旧版本快照，因为没有提交的快照读不到，没有互斥关系。

MVCC中事务的修改操作(Delete、Insert、Update)这些操作会给数据行新增一个版本快照。

### 版本号
MVCC里面有两个版本号:
- 一个是系统版本号，是递增的数字，每开始一个新的事务就将序号分配给事务，然后自己自动递增一下，用来保证每个事务都是唯一的序号。
- 另一个是事务版本号，新开一个事务时，分配的系统版本号。


### MVCC的Undo日志
MVCC的数据的快照存储在Undo日志中，该日志通过回滚指针ROLL_PTR把一个数据行的所有快照连起来。

如果进行了下面这样的操作:
> INSERT INTO t(id, x) VALUES(1, "a");  
UPDATE t SET x="b" WHERE id=1;  
UPDATE t SET x="c" WHERE id=1;  

由于默认的AUTOCOMMIT机制，每个操作都是一个单独的事务，其数据行的快照日志如下:
> 只有在进行修改操作时才会分配事务id，如果是只读事务，事务id默认为0

```
Record      Undo Update     Undo Update     
TRX_ID=3    TRX_ID=2        TRX_ID=1        Undo Insert
DEL=0    -> DEL=0      ->   DEL=0      ->   id=1
id=1        id=1            id=1
x='c'       x='b'           x='a'
```
对于INSERT、DELETE、UPDATE操作均会创建一条快照日志，同时记录事务版本号，DELETE是一个特殊的UPDATE操作，DELE字段会置为1。

### ReadView
**如何判断上面的哪条快照日志已经提交了呢**？  
MVCC维护了一个ReadView结构，主要是一个包含当前系统 **未提交事务ID的列表** TRX_IDS{TRX_ID1,TRX_ID2,......},这个列表还使用两个指针TRX_ID_MIN和TRX_ID_MAX分别指向这个列表里的事务最小版本号和事务最大版本号（也指系统版本号的下一个版本号），以及一个CREATOR_TRX_ID表示生成该ReadView的事务id，因为给事务版本号所分配的系统版本号是不断递增的，所以事务版本号在使用过程中也是不断递增。
> **ReadView何时创建** ？  
> 在RC隔离级别下，当前事务的每个Select都会获得最新的ReadView。
> 在RR隔离级别下，当前事务的第一个SELECT会获得最新的ReadView

那么就可以根据，这个最大最小版本号来判断事务有没有提交。
> 并不是所有的大于最小值并且小于最大值事务ID都在这个TRX_IDS列表里面，这个列表仅存未提交的事务ID

**当ReadView创建完成以后，要访问某条记录的判断步骤**
- 读取记录回滚指针的最新快照的事务ID，判断是否可读

  - TRX_ID < TRX_ID_MIN，表示这个数据行快照的事务在当前事务生成的ReadView前就已经提交了，数据行快照可以使用，直接返回
  - TRX_ID > TRX_ID_MAX，表示这个数据行快照在事务在当前事务生成ReadView以后才创建的，还不能使用，回滚指针指向数据行的下一个快照，再次判断是否可读
  - TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX，如果被访问的数据行快照的事务id在当前Readview的TRX_ID_MIN和TRX_ID_MAX之间，就判断数据行快照TRX_ID位于TRSX_IDS列表中表示该数据行快照对应的事务在ReadView创建时是活跃的还未提交，该快照不可使用。如果TRX_ID不在这个列表里，那么数据行快照已经提交了是可以使用的。

> 当TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX时，对于TRX_ID的判断逻辑是一致的，但是对于不同隔离级别的ReadView是有区别的。  
> 对于**RC**，其ReadView是每次最新的Commit以后的数据行快照，那么每次都能读取到最新的数据。  
> 对于**RR**，其ReadView是开启事务第一次读取时的快照，即开启事务前最后一次Commit，在这个事务里面之后每次读取获得的都是这个快照，即便对数据行进行了修改，也无法获得最新的数据行快照的Commit，保证了可重复读。

在读到的数据行不可使用时，沿着回滚指针ROLL_PTR找到下一个快照再次判断，直到找到一个可以使用的。


### 快照读与当前读
经过上面对MVCC的分析，应该已经了解到何为快照与当前了

#### 快照读
直接使用Select * from xxx 的语句，读取到的就是快照里的数据，不需要加锁即可读。

#### 当前读
获得最新的数据，即最新的Commit以后的数据行快照。
对于UPDATE、INSERT、DELETE操作会进行加锁操作来读取最新的数据，因此MVCC只是保证了SELECT不需要加锁。

在使用SELECT时也可以强制加锁。
> SELECT * FROM table WHERE ? lock in share mode;  
SELECT * FROM table WHERE ? for update;

#### MVCC与undo log日志的联系
undo log日志保存的是每条记录的不同事务id的数据记录，这些事务id的记录通过回滚指针往回指连接起来。然后系统生成了一个包含全局未提交事务id的readView结构，这时候读取了一条记录，知道了当前的事务id，如果当前读到的是未提交的事务id的记录，那么就到undo log日志里面去找，用回滚指针往前找，直到最新的已经提交的数据。


## InnoDB中的锁

### Record Locks
记录锁 通过对数据行的索引（不论是唯一索引还是非唯一索引，范围查询还是等于查询）进行加锁，而不是数据行本身，如果表没有设置索引，InnoDB会在主键上创建隐藏的聚簇索引。

### Gap Locks
间隙锁 锁住的是一段不包含记录的区间。
- 对于唯一索引，只有在范围查询时会加上Gap锁，等值查询直接在主键索引或者唯一键索引上加上记录锁即可。
- 对于非唯一索引，范围查询时会加上Gap锁，等值查询时也会加上Gap锁。

**那么加锁步骤是咋样的**？  
以非唯一索引的等值查询为例，其他两种范围查询比较好理解。
|id|value|
|-|-|
|1|97|
|2|98|
|5|100|
|6|101|
|112|200|
以上面表格为例进行一次select当前读查询，使用快照读可能会不加锁观察不到结果，value为非唯一索引
> select * from tb where value = 100 lock in share mode;

那么按照非唯一索引的查询步骤，到b+树去查询
|97|98|100|101|200|
|-|-|-|-|-|
|1|2|5|6|112|
然后到主键聚簇索引的b+树里去查询
|1|2|5|6|112|
|-|-|-|-|-|
|97|98|100|101|200|
查询步骤如下:  
- 首先去非唯一索引查询100，在100记录前后加上Gap锁，也就是(98,100)与(100,101)这个范围会加上Gap锁，100这个索引会加上Record锁，然后查询到100记录的主键id为5。
- 拿着查询到的主键id=5到主键聚簇索引b+树里面去查询所有数据，事先也会给id=5加上Record锁。

这下就理解了Gap锁给区间加锁不包括记录的含义。

> 在show engine innodb status\G输出中:  
如果是单纯的record lock，显示的是：locks rec but not gap  
如果是单纯的gap lock， 显示的是：locks gap before rec  
如果是gap+record，也就是next key lock，显示的是：lock_mode X <空>  

> 在RR隔离级别下才有Gap锁，在RC隔离级别下没有Gap锁，自然也就没有Next Key锁

> 以上Gap锁参考博客[MySQL InnoDB中唯一索引和非唯一索引时的加锁情况](https://www.cnblogs.com/yulibostu/articles/9712417.html)
、[Mysql加锁过程详解（8）-理解innodb的锁(record,gap,Next-Key lock)](https://www.cnblogs.com/crazylqy/p/7773492.html)

### Next Key Lock
NextKey Lock由Gap锁与Record锁结合而成，仍然是在RR隔离级别下，innodb_locks_unsafe_for_binlog参数为0即不取消Gap锁，那么Next Key锁会生效。

即除了锁住索引记录本身，还会锁住索引间的间隙。

那么对于每一个索引记录，其加锁范围为左开右闭区间。如果between 3 and 10 范围查询操作查到索引记录为 3，4，6，7，8，10，那么锁定的区间范围是:  
(上一个索引记录,3]  
(3,4]  
(4,6]  
(6,7]  
(7,8]
(8,10]  
整体看来就是(上一个索引记录,10]这个区间被锁住了。    

**那么什么情况下会加锁呢**？
> select...from   
> 不加任何类型的锁  

> select...from...lock in share mode  
> 在扫描到的所有索引记录上加共享的NextKey锁，然后到主键聚集索引上加排他锁

> select...from...lock for update
> 在扫描到的所有索引记录上加排他的NextKey锁，然后到主键聚集索引上加排他锁

> update...where delete from...where
> 在扫描到的所有索引记录上加排他的NextKey锁，然后到主键聚集索引上加排他锁

### 插入意向锁
插入意向锁是InnoDB用来提高多事务并发插入能力的锁，名字有意向但其实不是意向锁，而是间隙锁，也不是表锁，是行锁。

普通的Gap锁是防止在间隙里有新记录插入，只与插入操作冲突。可以说插入的时候是排他锁。  
但是对于插入意向锁而言，允许多个事务在同一段范围里插入数据，只要数据本身不冲突就不会阻塞。  

关于插入意向锁与其他锁的兼容关系:  
||Gap锁|插入意向锁|Record锁|Next-Key锁|
|-|-|-|-|-|
|Gap锁|兼容|兼容|兼容|兼容|
|插入意向锁|```冲突```|兼容|兼容|```冲突```|
|Record锁|兼容|兼容|```冲突```|```冲突```|
|Next-Key锁|兼容|兼容|```冲突```|```冲突```|
> 横向锁是已经获得的锁，纵向锁是正在申请的锁

Gap锁自身是兼容的，插入意向锁自身也是兼容的，Record锁自身是冲突的，但这不是重点。

问题是在已经获得了Gap锁或Next-Key锁以后，即便是同一事务，想要获取插入意向锁也会阻塞。

## 范式
### 第一范式
属性不可再分

### 第二范式
所有的非主属性列完全函数依赖于主键，即符合第二范式。    
可以将完全函数依赖的非主属性与主键一同拆分出去
> {Sno, Cname}为主属性唯一确定一条记录。   
> 有依赖关系 Sno, Cname-> Grade，那么可以将这三个记录完全拆分成为一张单独的表。

### 第三范式
存在非主属性传递函数依赖于主属性，这里的依赖可以是完全函数依赖也可以是部分函数依赖于主属性。如果是这种情况可以进行拆分。
> {Sno, Cname}为主属性唯一确定一条记录。   
> 有依赖关系 Sno -> Sdept -> Mname，那么可以将Mname移除原表，Sdept->Mname拆分为一张新的表。 

## InnoDB索引
### B+树
是一颗平衡排序二叉树。  
B+树基于B树与叶子节点的顺序访问指针来实现。具有B树的平衡性查找效率高且稳定，而且能通过顺序访问指针来提高区间的查询性能。

B+树的叶子节点暂存了所有的数据，中间节点使用叶子节点的数据作为索引来进行查找，最终能获得位于叶子节点的所有数据。

**怎么在B+树上面查找呢？**  
首先从B+树的根节点进行查找经过O(logn)时间以后，找到叶子节点，然后在叶子节点上顺序或者二分查找对于key的data。

插入和删除操作会破坏树的平衡结构，需要重新对树节点进行分裂、合并、旋转等操作。

### 与红黑树比较
红黑树也可以用来实现索引，但是文件系统与数据库普遍使用B+树来作为索引结构，那么有哪些原因呢？  
- B+树有更低的树高，平衡树的节点可以自定义，其树高为O(h)=O(logdN)【log以d为底的N的对数】，这个d就是一个中间节点出度的个数。红黑树的出度为2，而B+树的出度特别的大，所以红黑树的树高比B+树要高。
- 磁盘访问原理，操作系统将内存与磁盘分割成固定大小的块，内存中称为一页，与磁盘以页为单位交换数据。数据库系统将索引的一个节点大小设置为一页的大小，使得一次io就能完全载入一个节点（一个节点就是一个B+树的节点）。
- 磁盘预读特性，为了减少io操作，一次磁盘io往往不是严格按需读取，而是每次都会预读，预读的话是在磁盘访问寻道完成以后将找到数据的一页以及其后连续的几页读入内存，只需要少量旋转时间即可，通常预读取大小就是页的整数倍。

> 磁盘存取，磁盘I/O涉及机械操作。磁盘是由大小相同且同轴的圆形盘片组成，磁盘可以转动(各个磁盘须同时转动)。磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不动，磁盘转动，但磁臂可以前后动，用于读取不同磁道上的数据。磁道就是以盘片为中心划分出来的一系列同心环。磁道又划分为一个个小段，叫扇区，是磁盘的最小存储单元。  

> 磁盘读取时，系统将数据逻辑地址传给磁盘，磁盘的控制电路会解析出物理地址（哪个磁道，哪个扇区），于是磁头需要前后移动到相应的磁道——寻道，消耗的时间叫——寻道时间，磁盘旋转将对应的扇区转到磁头下（磁头找到对应磁道的对应扇区），消耗的时间叫——旋转时间，这一系列操作是非常耗时。

### Mysql索引
索引是通过具体的DB引擎实现的，比如InnoDB和Myisam等，不同的引擎，索引具有不同的类型和实现。
#### B+树索引
是大多数MYSQL存储引擎的默认索引类型。
InnoDB的B+树索引分为聚集索引与辅助索引，聚集索引的叶子节点存储完整的行记录，因此InnoDB必须有且只有一个聚集索引。  
- 如果定义了PK，那么PK就是聚集索引
- 如果没有PK，那么第一个NOT NULL UNIQUE列是聚集索引
- 否则InnoDB会创建一个隐藏的row-id作为聚集索引

辅助索引的叶子节点存储着主键的值，而非完整记录，因此使用辅助索引先要在辅助索引B+树里面找到聚集索引主键id然后再到聚集索引里面查找数据行。

#### 哈希索引
哈希索引时间复杂度O(1)很高，但是不能排序，分组，也不能进行范围查询，只能精确查找。

但是InnoDB有一个特殊的功能叫"自适应哈希索引"，对于频繁使用的某个索引值，会在B+树之上再建立一个哈希索引，是B+树的索引再具有哈希索引的一些优点。

#### 全文索引
MyISAM存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。  
全文索引使用倒排索引实现，记录着关键词到其所在文档的映射。

> 倒排索引？doyouknow？   
> 就是将整个文章按每一句进行编号，每一件编号里有哪些文章语句和单词，倒过来存，怎么个倒过来存呢？就是将这些文章句子中的关键词提取出来，记录这些关键词出现在了哪几句编号中。  

### 索引优化
#### 索引列 必须独立使用
在进行查询时使用索引，索引列不能位于表达式的一部分，也不能是函数的参数，否则不会使用索引列。
```sql
SELECT actor_id FROM actor WHERE actor_id + 1 = 5;
```
上面的例子不会使用actor_id索引。

#### 联合索引
我们知道联合索引满足最左前缀原则，即以最左边的列为起点任何连续的索引都能匹配上。

所以创建索引时，要将最频繁使用的列放到最左边，而且对于or字段，如果or两边有一个字段没有索引，就会放弃使用索引改用全表扫描。

**例**：  
我们给(a，b，c) 三个属性列创建这个顺序的联合索引，相当于创建了(a)单列索引、(a，b)联合索引、(a，b，c)联合索引这三个索引。

那么上面这三个索引的叶子节点均保存了对应索引列的全部数据。

> 参考博文[MySql | InnoDB 多个单列索引与联合索引之路](https://blog.csdn.net/liujun19921020/article/details/103215701)

#### 索引列的选择性
让选择性最强的索引列放到最前面。

在抛开业务需求的基础上，如何选择一个列放在索引的最左边呢？  
根据索引的选择性(不重复的索引值和记录总数的比值)，最大为1，此时每个记录值都有唯一的索引与他对应，查询的效率最高，以唯一索引为例，。

#### 前缀索引
对于BLOB、TEXT、VARCHAR等文本类型的列，必须使用前缀索引，只索引数据开始的部分字符。

选多长的数据作为前缀，要根据索引的选择性来确定，以使得索引选择性接近1.

#### 覆盖索引
索引列包含需要查询的所有字段。
 
覆盖索引是一种设计思路，其具有以下优点:
- 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
- 对于InnoDB引擎，如果辅助索引能够覆盖查询，则无需访问主索引进行回表操作，与直接进行主键查询具有相同的效率。

覆盖索引常常使用联合索引来实现，叶子节点中包含查询索引列的所有值，不再需要进行回表操作。

使用explain 能观察到Extra字段显示Using Index，触发了覆盖索引。

#### 索引下推
指的是在使用索引进行查询的时候，查询到非聚集索引的叶子节点的索引的时候，先用where语句对叶子节点存在的部分字段的值进行过滤，然后再用剩下的记录去做回表。

### 索引的优点

- 大大减少扫描的数据行数
- 索引是有序的，避免进行排序和分组以进行的临时表创建
- 将随机io变为顺序io(有序的数据可以相邻存储)

### 索引使用条件
- 对于小表，不需要建立索引，因为有可能全表查询比索引要快。
- 对于中表到大表，索引非常有效率
- 对于超大表，建立维护索引的成本也特别高，这种情况下可以进行分表查询。

### 查询性能优化

#### 使用Explain分析Select
> explain select id,name from user where name = 'sail';

|id|select_type|table|type|possible_keys|key|key_len|ref|rows|Extra|
|-|-|-|-|-|-|-|-|-|-|
|1|SIMPLE|user|ref|name|name|23|const|1|Using where;Using index|

其中比较重要的字段包括：  
- id: id相同认为是同一组，从上到下顺序执行，id不同认为越大优先级越高
- select_type: 查询类型，有简单查询（不包含子查询和UNION）、联合查询、子查询、PRIMARY（里层包含任何复杂的子部分，外层就会标记为这个）等
- key: 有没有使用索引，使用的什么字段索引
- rows: 查询时扫描了多少行，越少越好
- Extra: 十分重要的额外信息，例Using where(使用了where过滤) 等等

#### 优化数据访问
1. 减少请求的数据量
      1. 不要使用全表查询，select *等排除使用
      2. 有计划的限制返回的数量，使用limit等
      3. 缓存重复查询数据
2. 减少服务端扫描数据的行数
      1. 使用索引覆盖查询

#### 重构查询方式
1. 切分大查询
      - 对于大表，如果执行一次性查询，可能速度慢，锁住很多数据，占满事务日志，阻塞其他重要的小查询。  
      - 因此要切分出来，多次查询，比如使用limit进行分页查询
      - 对于小表多次查询会影响效率，对于大表反而能提升效率

2. 分解大连接查询  
将联表查询分解为多次的单表查询，然后在业务中关联。
      - 让缓存更有效率
      - 根据前一个查询决定后续查询条件，减少联表带来的冗余查询
      - 减少锁竞争
      - 在应用层连接

### 存储引擎
#### InnoDB
是MYSQL的默认引擎。  
实现了四个标准的隔离级别。  
索引分为主索引与辅助索引两部分，主索引为聚集索引，索引中就保存了数据不需要直接读硬盘。  
支持在线热备份。  

#### Myisam
对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。  
不支持事务。  
不支持行锁。  

#### 比较
事务：InnoDB是事务型的支持Commit与RollBack
并发：Myisam支持表级锁，InnoDB支持行级锁
外键：InnoDB支持外键
索引：InnoDB索引是聚集索引，数据放在主键叶子节点，Myisam是非聚集索引，数据与索引分离。
行数：InnoDB不保存行数，Myisam保存行数
备份：InnoDB支持在线热备份
崩溃恢复：Myisam发生崩溃后数据丢失损坏的概率比InnoDB要高，而且速度也慢
其他特性：Myisam支持全文索引、压缩表和空间数据索引

### Mysql数据类型
#### 整型
TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好。

INT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的。
#### 浮点型
FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。

FLOAT、DOUBLE 和 DECIMAL 都可以指定列宽，例如 DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。
#### 字符串型
主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。

VARCHAR 这种变长类型能够节省空间，因为只需要存储必要的内容。但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。

在进行存储和检索时，会保留 VARCHAR 末尾的空格，而会删除 CHAR 末尾的空格。
#### 时间日期
MySQL 提供了两种相似的日期时间类型：DATETIME 和 TIMESTAMP。

##### DATETIME  
能够保存从 1000 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间。

它与时区无关。

默认情况下，MySQL 以一种可排序的、无歧义的格式显示 DATETIME 值，例如“2008-01-16 22:37:08”，这是 ANSI 标准定义的日期和时间表示方法。

##### TIMESTAMP
和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年到 2038 年。

它和时区有关，也就是说一个时间戳在不同的时区所代表的具体时间是不同的。

MySQL 提供了 FROM_UNIXTIME() 函数把 UNIX 时间戳转换为日期，并提供了 UNIX_TIMESTAMP() 函数把日期转换为 UNIX 时间戳。

默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间。

应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。

### Mysql分表策略
> 40亿条用户记录存放到mysql中，要使用用户名与手机号进行查询，设计一个方案保证查询效率？   
> 首先进行 分库 按照 用户id范围进行分库。   
> 然后对每一个库按照 用户id范围进行分表。
> 然后对用户名维护一个按照用户名分库分表的多个表。
> 对手机号维护一个按照手机号分库分表的多个表。
> 那么就是如果要以手机号查询，首先按照hash求得手机号对应得库，再hash求得手机号对应得表，走索引取得记录对应得主键id，拿着主键id，按照id范围获得主键id表的库，再按id范围获得主键id的分表，进而走索引获得对应的用户记录。
> 以用户名查询类似。

#### 水平切分
水平切分又称为Sharding，它是将同一个表中记录拆分到多个数据结构相同的表里面。  
当一个数据表的数据不断地增多，到不论怎么优化都难以使用时，必须要进行Sharding。
将数据分散到集群的多个表里面，缓解单个数据库的压力。

#### 垂直切分
垂直切分是将一张表的属性字段切分到多个表里面，通常按关系密集程度切分，也可以按使用频率来切分。

通过切分来缓解表的冗余数据。

#### 水平切分策略
- 哈希取模hash(key)%N (N指切分出的表的数量)
- 范围：按id范围或者时间范围，一段ids或者一段时间内的位于一张表里
- 映射表：自定义映射关系，使用单独的库表来存储这个映射关系，但是每次查询都是查两次表，路由映射表大了以后也会影响性能。

#### 水平切分的问题
1. 事务一致性问题  
   使用分布式事务解决 【怎么实现的？】
2. 连接问题
   1. 表的连接问题，对于无法连接的表采用单表查询后再条件查询

3. ID唯一性问题。
   1. 使用全局唯一ID
   2. 为每个分表指定一段ID范围
   3. 使用分布式ID生成器 【怎么实现的】

总的来说，分表为了解决存储的压力。



### Mysql复制
> 为什么 在 RC 级别下，binlog 格式要设置成 row？
> 
先来看下 binlog 的三种格式：
- binlog-format=STATEMENT ：在 Master 向 Slave 同步时，会以原生的 SQL 语句进行同步。
- binlog-format=ROW ：Master 会把被操作后的表中的行记录在日志中， 向 Slave 同步。简单来说同步的就是表中的数据。
- binlog-format=MIXED ：默认会以 STATEMENT 的方式记录，但在一些情况下可以自动的切换成 ROW 方式，比如执行用户自定义的函数 UUID.

这里采用反证法，如果在 RC 级别下，将 binlog 的格式设置成 Statement 会发生什么？ 

还是使用之前 RR 级别下幻读的例子：
|Session A|Session B|
|-|-|
|begin:||	
|update t set d=100 where d=5;||
||insert into t values(1,1,5);|
||update t set d=5 where id=1;|
|commit;||

得到的结果是一样的，Binlog 日志中 Session B 先执行，Session A 后执行，A 会把 id=1 中 d 的值改为 100，出现了 binlog 和 数据库数据不一致的现象。

而基于 ROW 格式则不同，binlog 日志中记录的是被操作后的数据，不是重新执行 SQL 自然就没有这个问题。

#### **主从复制**
Mysql有一种二进制日志bin-log，会记录下所有修改数据库的sql语句。
- 那么在主服务器中启用binlog线程将数据更改写到日志中  
- 在从服务器中启动一条io线程根据MYSQL协议向主服务器请求bin-log日志
- 主服务器开启一条Dump线程，检查自己二进制日志的事件，如果请求的事件不带位置参数，那么主服务器会将第一个bin-log开始，一个一个发给从服务器
- 从服务器接收到这些数据以后会放到那个中继日志(Relay log)，并记录请求到主服务器哪一个binlog文件的哪一个位置。
- 从服务器启动另一个sql线程，解析中继日志并执行一遍。

#### **读写分离**
主服务器处理处理写操作与实时性较高的读操作，而从库处理读操作。
读写分离极大地提高了访问的能力，提高的是被写入影响的查询的效率，原因如下：
- 主从服务器各自负责写和读，缓解了锁的竞争，提高并发效率。
- 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销。

读写分离可以通过中间层来实现，在应用服务器与数据库服务器之间添加一层中间代理层，代理层接收应用层的读写请求，然后决定转发到哪个服务器上。

#### 主从复制的延迟问题
从库单线程执行sql的延迟问题，无法从主从复制架构上解决，从上层找解决方案：  
1. 可以将更新完数据之后的读取相关数据的操作，都去读主库。
2. 利用分布式缓存，在更新完数据以后的同时将这些数据写入到缓存中，避免立即去读从库。



# Mysql存储的原理
在InnoDB中数据持久化到磁盘上对应一个.frm文件存放表的定义，对应一个.idb的文件存放数据与索引。

可以说在InnoDB中所有数据都是索引。

# 关于InnoDB的普通索引与唯一索引
考虑都是非主键索引的情况。

B+树的叶子节点保存的是索引值与主键id。

## 更新过程
首先会存在一个change buffer，当要更新一个数据页的时候，如果数据页在内存中就直接更新，如果不在内存中，那么等下次查询访问到这一页数据的时候将数据读入内存中以后，执行change buffer中的与当前页相关的修改操作，为了保证持久性，这个change buffer也是会持久化到磁盘的。通过这种方式能减少读磁盘的次数。而且磁盘的数据提前读入内存会占用buffer pool的，提高内存利用率。

以上对于普通索引是能够提高查询效率，以及磁盘访问效率的。

对于唯一索引，由于要进行数据唯一性验证，需要先将数据页读入内存，因此就不需要使用change buffer了。

当插入一条数据的时候，如果插入的物理页在内存中，就直接插入就ok了，如果不在内存中呢，就写到change buffer中，然后将物理页的修改还是插入操作写入到redo log中。

以上内存操作完成以后，一次磁盘io写入即可，顺序写。
