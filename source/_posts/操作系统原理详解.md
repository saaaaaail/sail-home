---
title: 操作系统原理详解
date: 2020-07-02 20:40:59
tags:
- 操作系统
- linux
---

# linux操作系统原理详解
最近要系统性的复习操作系统准备面试，决定结合linux来一起看看操作系统原理。参考《深入理解Linux内核(第三版)》

## 进程管理
进程被定义为程序执行时的一个实例。
### **进程描述符**  
进程描述符为进程控制块PCB，与进程一一对应，由进程描述符指针指向，在Linux中定义为task_struct类型的结构，描述进程的基本信息和运行状态。

进程描述符和进程的内核态堆栈存放在一个单独的8kb内存区中。esp寄存器指针指向栈顶。这俩东西配对存储，使得很容易通过esp指针获得进程描述符的指针。
### **进程状态**  
**可运行状态**:要么占用CPU执行，要么准备执行。  
**可中断的等待状态**:进程被挂起，直到一个条件，一个信号传递过来唤醒经常。  
**不可中断的等待状态**:进程必须等待，不能被中断，直到特定的事件发生。  
**暂停状态**:进程的执行被暂停。  
**僵死状态**:进程执行被终止，但是父进程还没有进行wait系列的系统调用返回死进程的信息。在发布wait()系统调用之前，内核不能丢弃包含在死进程描述符里的数据，父进程可能还需要他。

### **进程切换**
进程切换只发生在内核态
#### 硬件上下文
进行进程切换之前要保存当前进程的硬件上下文，替换为目标进程的硬件上下文。进程的硬件上下文部分保存在（104字节的任务状态栈）TSS段，剩余部分保存在内核态堆栈。

### **进程创建**
在linux系统中，系统启动以后第一个进程由系统来创建，其余进程都必须由已存在的进程来创建，创建一个子进程的系统调用为fork()，我们都知道一个进程的数据包含BSS段、数据段、代码段、堆、栈五部分，fork()创建进程会复制父进程的这些数据结构，但是不是与父进程共享而是单独分配的内存，fork在linux中使用的写时复制技术，刚开始是共享父进程数据段，在写数据段时才会进行复制。

### **内核线程**
内核经常需要在后台执行一些耗时操作，就通过内核线程来实现，只在内核态运行，也没有独立的地址空间

### **撤销进程**
进程终止的一般方式为调用exit()系统调用。

### **进程调度**
linux调度策略是基于优先级排队的，每个进程都与一个值关联，这个优先级是动态的，对于长时间没有使用CPU的的进程动态提升他们的优先级，对于已经占用CPU很长时间的进程动态减少优先级来处罚。

一般将进程区分为三类:  
#### **交互式进程**:
进程经常与用户交互，需要花时间等待用户操作，当输入被接受时，必须很快唤醒进程。
##### 时间片轮转
将所有的就绪的进程按照FCFS的顺序排成一个队列，每次调度把CPU时间分给队首进程，该进程可以执行他获得的时间片，时间片用完了就触发定时中断，挂起该进程并排到队尾，继续给此时对头的进程分配时间片。
- 时间片轮转的效率与一次分配的时间片有关系，太短了导致进程切换频繁，CPU利用率低，太长了就没有实时性了。
##### 动态优先级调度
为每个进程分配一个优先级，按进程优先级进行调度，而且会动态修改进程的优先级。

linux采用的此种方式进行优先级调度。会给每个进程都分配两种优先级。
- **静态优先级** 这种优先级由用户赋给实时进程，范围由1到99，越小优先级越高，调度程序不会改变他。
- **动态优先级** 这种优先级只用于普通进程，实质上它是基本时间片与当前时期内剩余时间片之和。

linux进行调度需要的数据结构都记录在进程描述符中，包括以下几个域，简单记录下：
- need_reached 由ret_from_intr()检查的一个标志，决定是否调用schedule()函数
- policy 调度的类型，可选值如下:
  - SCHED_FIFO 先入先出的实时进程
  - SCHED_RR 循环轮转的实时进程
  - SCHED_OTHER 普通的分时进程
  - SCHED_YIELD 当进程调用sched_yield()系统调用时，这个标志被设置。调度程序就把进程描述符放在运行队列的尾端。当内核在执行一个较长且不紧急的任务时，又希望给其他进程机会，就会设置这个标志，并调用schedule()
- rt_priority 实时进程的静态优先级 普通进程用不到
- priority 进程的基本时间片 又称为基本优先级
- counter 当前时间片用完之前剩余的CPU时间节拍 在update_process_times()函数每个节拍都会将当前进程的counter-1
  
以上参数中，priority与counter对于普通进程而言决定了进程的分时与动态优先级，对于SCHED_RR实时进程只用来分时，对于SCHED_FIFO实时进程用不到。

##### 多级反馈队列
一个进程需要执行100个时间片，如果采用时间片轮转，那么需要交换100次。

多级队列为这种需要连续执行多个时间片的进程考虑，里面设置了多个队列，每个队列对应了线程能执行的时间片的长短，例如分为1、2、4、8...等时间片，第一个队列入cpu执行，如果没执行完会进入第二个时间片长一点的队列，依次类推。

最上面的时间片最短的优先级最高，只有上一个队列没有进程在排队，才会执行后面的队列。

#### **批处理进程**:
经常后台运行，不必有很快的响应,保证吞吐量和周转时间。
##### 先来先服务 FCFS
非抢占式的调度算法，有利于长作业，但不利于短作业，短作业必须长时间等待前面的长作业执行完。
##### 短作业优先 SJF
非抢占式的调度算法，保证运行时间短的作业优先运行，一直有短作业到来的话，有可能使长作业饿死。
##### 最短剩余时间优先 SRTN
短作业优先的抢占式算法，按剩余运行时间的顺序进行调度，当新的作业到来，其整个运行时间比当前进程剩余时间要短，则挂起当前进程，运行新来的进程。
#### **实时进程**:
有很强大的调度需要，绝不会被低优先级进程阻塞，必须要有很短的响应时间。    
实时系统分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

### **进程同步**

#### 临界区
对临界资源(临界资源指的是一次仅允许一个进程使用的资源，硬件如打印机、磁带机，软件如消息队列、变量、缓冲区等)进行访问的代码被称为临界区，为了能正常安全地访问临界区资源，每个进程进入临界区之前要进行检查。

#### 同步与互斥
**同步** :同步指多个进程合作完成某个任务，但是这些进程之间有先后顺序的要求，必须按照一定的先后顺序执行。
**互斥** :多个进程同一时刻只能有一个进程进入临界区。

#### 信号量
信号量是一个整型变量，可以对其进行down与up操作，也就是PV操作

down，如果信号量大于0，执行-1操作；如果信号量等于0，进程睡眠，等待信号量大于0并且被唤醒。

up，对信号量执行+1操作，并且唤醒睡眠的进程让其完成down操作。

以上两个操作必须是原语，在linux中通常会提前关中断，执行完以后开中断

#### 管程
由于信号量的机制，PV操作成对出现，但是位置分散，而且使用不当会造成死锁，因此提出了管程的机制。
管程的特点就是某个时刻只能有一个进程/线程使用管程。而且在不满足某个条件变量的时候能自我阻塞退出管程等待唤醒，等待其他进程/线程获得管程执行后唤醒其他进程/线程。

>所以在java中synchronized关键与Lock锁都实现了类似管程的功能。  
简单记录下synchronized的管程理解。  
**监视者对象**:Monitor Object负责公共的接口方法，java中的Object就是监视者对象。  
**同步块**:在获得了监视者对象以后，才能执行这块代码，保证了同一时刻只有一个线程执行。  
**监视锁**:Monitor Lock 每个监视者对象都会有一把监视锁。
**监控条件**:Monitor Condition 根据是否获得锁以及是否满足监控条件来决定阻塞还是唤醒进程/线程

#### 同步问题的sail实现
##### 生产者消费组队列
##### 哲学家就餐问题
##### 读者-写者问题

### **进程通信**

为了能达到进程同步的目的，需要让进程间进行通信，传输一些同步必须的数据。

#### 管道
管道是一个固定大小的缓冲区，只支持半双工通信，只能在父子进程和兄弟进程间使用。

可以c++里面通过调用pipe函数创建，fd[0]用于读，fd[1]用于写。
```c++
#include <unistd.h>
int pipe(int fd[2]);
```
#### 命名管道
与管道相同，只是去除了只能父子进程、兄弟进程通信的限制。

借助c++的mkfifo函数来创建。管道实际是一个file结构和一个VFS索引，也就是一个虚拟的文件。常用于客户进程与服务端进程间的通信，客户进程写完了以后，服务进程去读，服务进程写完了以后，客户进程去读。
```c++
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

#### 信号signal
信号具有平台相关性，不同平台下能使用的信号种类不同也十分有限，用于通知进程某事件的发生。

#### 消息队列
消息队列独立于进程存在，不需要进程维护管理。
消息队列提供了同步阻塞的方法，不许进程自己提供。
读进程能有选择地接收不同类型的消息。

#### 信号量
是一个计数器，也能称为互斥量，能控制进程同步的访问共享资源。

#### 共享内存
允许多个进程共享一片存储区域，因为数据不需要在进程间复制效率很高，但是对共享数据访问的话要使用使用同步机制保证数据安全。

#### 套接字
指定ip与端口能实现相同机器或者不同机器间的通信。

<!-- ## 操作系统的死锁问题
### 发生死锁的必要条件
根据死锁可以推出以下四种情况：
- 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

### 处理方法

#### 死锁检测与恢复


#### 死锁预防
#### 死锁避免 -->

### 内存管理
#### 虚拟内存
虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用空间。

操作系统将内存抽象为地址空间。每个程序拥有自己的地址空间，地址空间被分割成多个块，每一块被称为一页，这些页在使用的时候会被映射到实际的物理内存（可以不连续），不需要所有页都必须在物理内存中，如果使用到一页不在物理内存中，则会引发缺页异常，由硬件重新分配缺失的物理内存，并重新执行。

因此，虚拟内存技术保证了程序运行时不需要将虚拟地址每一页都映射到物理内存，仅仅只是用多少映射多少，所以使得有限的物理内存运行大程序成为可能。

#### 分页系统地址映射
内存管理单元（MMU）管理着虚拟地址（线性地址）和物理内存的转换，其中页表（Page table）存储着页（虚拟地址空间）和页框（物理内存地址）的映射关系。
>对于linux而言，内存映射主要靠的页式内存管理机制，页机制是现代CPU都具备的，而段式内存管理是intel86系统架构独有的概念。linux中为了保证兼顾intel86平台先分段再分页的规则，使虚拟地址具有了相同的段基址 【0(段基址):偏移量(通过段基址+段内偏移量得到的是线性地址)】（这个 段基址:偏移量 的地址组合出现在段式内存管理里面，称为逻辑地址），所以实际上linux中的逻辑地址与线性地址是一致的。

了解了各个地址的关系以后，研究一下页式管理的虚拟地址的构成。

一个虚拟地址可以区分两块:页面号和页面内偏移量。
对于一个32位linux系统，其页框大小为4kb，那么使用2^12表示偏移量即可全部寻址，高位的20位均可以表示页面号，根据操作系统书本的描述，页面号乘以页表项的长度加上页表的起始地址即可获得页表项在页表中的位置，根据这个位置号能获得物理块号的地址。将物理块号作为高位，将页面内偏移作为低位完成拼接即可获得页框的物理地址。

#### 页面置换算法
因为内存大小有限，访问的页面可能不在内存中，这时候发生缺页中断而将这一页从磁盘中调入内存。如果页面已经满了，那就必须从内存里选一个页面出来保存新的数据。

##### 最长时间内不再被访问 OPT
理论上的最优算法，所换出的页面是最长时间内不再被访问，但是因为无法知道一个页面的多长时间内不会再被访问。可以保证最低的缺页率。

##### 最久未使用LRU
无法知道未来使用内存的情况，但是可以根据过去使用内存的情况来替换，最久没有使用过的页面可以替换掉。

##### 最近未使用NRU
每个页面有两个状态:R与M ，当页面被访问时设置R=1，当页面被修改时设置M=1，R会定时被清零。  
将页面分为以下四类:
- R=0,M=0
- R=0,M=1
- R=1,M=0
- R=1,M=1
NRU 优先替换出已经被修改的脏页面（R=0,M=1），而不是频繁访问的干净页面（R=1,M=0）。

##### 先进先出FIFO
无法保证页面的命中率，随缘。

##### 第二次机会算法
将页面构造成一个FIFO队列，每个页面有一个标志位R，被访问或者被修改的将R=1,队列满的时候判断即将出队的页面R如果等于0，就直接让他出队，如果R==1，则将R置为0并把这个页面重新入队。

##### 时钟
第二次机会算法需要在队列中移动页面，影响效率。时钟算法不用移动页面节点，将页面构建成一个环，用一个指针指向最先入队的节点。

#### 分段
为了解决 内存地址空间不隔离，内存地址不固定 这俩问题，引入了分段的概念.
首先，分段在程序编译期间会建立多个表。
>在编译过程中会建立许多的表，来确定代码和变量的虚拟地址：  
1.被保存起来供打印清单的源程序正文；  
2.符号表，包含变量的名字和属性；  
3.包含所有用到的整形和浮点型数据的表；  
4.语法分析树，包括程序语法分析的结果；  
5.编译器内部过程调用的堆栈。  

前四个表在编译期会动态增长，如果使用分页地址就会被覆盖。  
这多张表分成逻辑上的多个段，逻辑上连续的地址空间。   

如果仅仅使用分段机制管理内存，那么这一张段表就对应一块连续的物理内存地址，逻辑地址的构成是段基址+段内偏移地址，根据段基址计算再到段表去查询获得物理地址的基址加上偏移地址就获得了实际的物理地址。但是在段式管理下，由于分配的内存不是定长的，时间长了，就会碎片化，导致有足够的内存空间但是无法分配给某个进程。

#### 段页式
段页式就解决了 内存地址空间不隔离，内存地址不固定，内存使用率不高 这仨问题。
首先段式管理解决了上面俩问题。

在段页式机制下面，程序内存地址被分成了多个连续的地址空间的段，在段内又分成了地址空间大小一致一般为4kb的页，解决了地址空间连续，利用率不高的问题。
段页式机制下，由段表计算出来的地址被称为线性地址，也就是分页里面的虚拟地址，将这个地址进行拆分，前一部分表示页面号，后一部分表示页面内偏移地址，页面号经过计算到页表中查询获得页的起始地址，加上页面内偏移就能计算得到实际的物理地址。

#### 分页与分段的比较
对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。

地址空间的维度：分页是一维地址空间，分段是二维的。

大小是否可以改变：页的大小不可变，段的大小可以动态改变。

出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。


